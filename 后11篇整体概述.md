## **16.** Robot Navigation in Unknown and Cluttered Workspace with Dynamical System Modulation in Starshaped Roadmap

**在未知且复杂环境中基于星形路径图和动力系统调制的机器人导航**

这篇论文提出了一种在**未知杂乱环境**中实现机器人高效导航的创新框架。以下围绕研究背景、核心问题及贡献进行概括性总结：

---

### **研究背景**
1. **环境挑战**：  
   在未知且障碍物密集的环境中（如灾后废墟、仓库），传统导航方法存在局限性：
   - **保守性**：基于椭圆/凸多边形（如安全走廊SC）的自由空间表示法无法充分利用传感器信息，导致路径规划过于保守。
   - **实时性不足**：现有星形区域（starshaped）表示法缺乏高效的实时参数化和运动控制方案。
   - **局部最优陷阱**：势场法（APF）等局部控制器易陷入局部极小值；动态系统调制（DSM）需依赖障碍物先验几何信息，难以处理未知环境。

---

### **核心研究问题**
如何设计一种框架，能够：
1. **实时构建非保守的自由空间表示**，最大化利用传感器数据覆盖可通行区域；
2. **生成动态路线图**，支持高效路径搜索与死锁处理；
3. **实现无先验知识的实时安全控制**，适应复杂障碍物布局。

---

### **提出的贡献**
#### 1. **星形动态路线图（Starshaped Roadmap）**
   - **表示方法**：  
     将激光雷达点云转换为极坐标，用**分段多项式**实时拟合星形区域边界，相比椭圆/凸多边形覆盖面积提升约 **30%**（图1c-e）。
   - **路线图构建**：  
     通过边界点聚类生成**前沿点（frontier points）**作为节点，构建增量式连通图，标识"可扩展"与"死锁"状态。
   - **死锁处理**：  
     动态更新机制：当机器人抵达前沿点无法扩展新区域时，标记为"stuck"并重新规划。

#### 2. **基于DSM的实时反应式控制器**
   - **高频调制**（200Hz）：  
     在星形区域内设计DSM控制器，通过调制矩阵 **M(p)** 调整运动方向：
     - **特征向量**：径向向量 **r(p)** 控制趋近边界速度，切向向量 **eᵢ(p)** 控制安全方向自由度。
     - **权重融合**：对重叠星形区域加权融合（式13-14），实现平滑过渡。
   - **机器人形状补偿**：  
     引入最近障碍点 **pₙ** 修正控制向量（式15），适配盘形机器人几何。

#### 3. **系统性能验证**
   - **仿真实验**（Gazebo）：  
     - **森林场景**：成功率 **96%**（DSM仅 **42%**），路径长度缩短 **15%**。  
     - **迷宫场景**：成功率 **94%**，实时计算耗时 **4.37±1.16ms**。
   - **实物实验**：  
     差分驱动机器人在 **6m×8m** 杂乱环境中平均速度 **0.4m/s**，控制延迟 **≤3ms**（图6）。

---

### **关键创新点**
- **非保守空间表示**：星形区域最大化利用传感器数据，减少路径冗余。
- **路线图-控制协同**：动态路线图提供全局视野，DSM控制器实现局部避障，克服传统方法的短视行为。
- **死锁实时处理**：通过节点状态更新机制应对未知环境中的死胡同问题。

> **实验结论**：相比DSM、FOA等方法，该框架在成功率和路径效率上显著提升，适用于无地图复杂场景导航。代码已开源：**github.com/kkkkkaiai/starshaped_roadmap**。



## **17.** Overlapping Social Navigation Principles: A Framework for Social Robot Navigation
**重叠的社交导航原则：社会机器人导航框架**

以下是对论文《重叠社交导航原则：社交机器人导航框架》的严格分析，基于论文内容提炼研究背景、核心问题及贡献：

---

### **研究背景**  
1. **社交导航的复杂性**  
   - 传统方法将人类视为静态障碍物 [1,2]，但实际需将人类视为交互主体，机器人行为需提升周围体验 [3]。  
   - 现有原则（安全性、舒适性、可读性等）定义模糊且交互关系不明，例如机器人说“借过”可能同时涉及礼貌性、可读性、社会能力 [4]。  
   - **关键矛盾**：多原则重叠导致系统设计复杂化，需明确核心原则及其权重。  

---

### **核心研究问题**  
1. **原则优先级问题**  
   - 哪些核心原则对社交机器人导航（SRN）最关键？  
   - 原则之间如何相互影响？例如：违反社会规范是否导致感知安全性下降？  
2. **量化评估缺失**  
   - 缺乏针对SRN场景的标准化量表（社会规范、感知安全性、可读性）。  

---

### **提出的贡献**  
#### 1. **重叠社交导航原则框架**  
   - **核心三原则**：  
     - **社会规范**（Social Norms）：机器人遵循文化惯例（如走廊靠右行）[6,15]。  
     - **感知安全性**（Perceived Safety）：超越物理安全，涉及速度、距离、肢体动作等主观感受 [22-24]。  
     - **可读性**（Legibility）：通过动作清晰传达目标意图（如手势指示方向）[30,31]。  
   - **原则交互性**：框架强调三原则重叠影响（图1a），例如可读性提升感知安全性，社会规范增强可读性 [44]。  

#### 2. **实验验证与量表开发**  
   - **视频实验设计**：  
     - 制作4种视频：① 理想通行（三原则全满足）；②-④ 分别禁用单一原则（图1b, 图2）。  
     - 166名参与者排序视频并填写量表（表I）。  
   - **关键发现**：  
     - **理想通行排名最高**（显著优于其他，\( p<0.001 \)）。  
     - **社会规范主导性**：禁用社会规范被评为最差（图3），且显著降低感知安全性（表III）。  
     - **原则互依性**：禁用任一原则均降低其他原则评分（如禁用可读性导致社会规范评分下降）。  
   - **首创量表**：  
     - 开发三原则的6点李克特量表（表I），信度（\( \alpha \geq 0.85 \)）达心理学标准 [91]。  

#### 3. **开源系统与工程实现**  
   - **机器人平台**：基于Spot四足机器人（带6自由度机械臂）。  
   - **算法实现**：  
     - **社会规范**：路径规划启发式算法，添加走廊右侧偏好代价矩阵（Algorithm 1）。  
     - **感知安全性**：双速控制（安全速度 \( 0.5 \, \text{m/s} \) vs. 不安全 \( 1.3 \, \text{m/s} \)，Algorithm 2）。  
     - **可读性**：机械臂手势指示路径意图（如转弯前指向走廊右侧，Algorithm 3）。  
   - **代码开源**：完整SRN行为栈发布于OSF平台 [53-55]。  

---

### **关键结论与启示**  
- **社会规范优先**：三原则中社会规范影响最强，其缺失导致最差用户体验（图3）。  
- **系统设计准则**：SRN需同时满足三原则，且需考虑其重叠效应（如安全行为需通过可读动作表达）。  
- **局限与未来**：  
  - 实验依赖视频排序而非实地交互；  
  - 需扩展更多原则（如礼貌性）、动态场景验证；  
  - 量表需进一步效度检验。  

> **原文总结**：“机器人需通过遵循社会规范、确保感知安全性和行为可读性来优化社交导航，其中社会规范是最关键因素。”（Section V）  

---
**分析依据**：严格遵循论文中的定义（Section I）、实验设计（Section IV）、数据结果（图3, 表II-IV）及结论（Section V-VII）。未引入外部知识。

**18.** ==***SafePCA: Enhancing Autonomous Robot Navigation in Dynamic Crowds Using Proximal Policy Optimization and Cellular Automata***==
**SafePCA：结合近端策略优化和元胞自动机提升动态人群中的自主机器人导航**

##  **19.** VLM-Social-Nav: Socially Aware Robot Navigation through Scoring Using Vision-Language Models
**VLM-Social-Nav：基于视觉语言模型评分的具社交意识的机器人导航**

以下是对论文《VLM-Social-Nav: 基于视觉语言模型评分的社会感知机器人导航》的严格分析，基于论文内容提炼研究背景、核心问题及贡献：

---

### **研究背景**  
1. **社交导航的挑战**  
   - 机器人在人机共存环境（如送货、服务场景）需满足**社会合规性**（social compliance），包括安全、文化习惯和情境适应性 [4,5]。  
   - **情境理解困难**：人类行为和环境上下文难以数学建模，传统方法依赖**数据驱动**（模仿学习/强化学习），需大量训练数据且泛化性差 [9-11]。  
   - **语言模型潜力未开发**：VLMs具备常识推理和情境理解能力 [15,16]，但存在**实时性缺陷**（高延迟），未应用于社交导航 [18]。  

---

### **核心研究问题**  
1. **如何实现无数据依赖的社交导航**？  
   - 避免传统方法对大规模数据集（如SCAND [11]）的依赖。  
2. **如何利用VLM理解社交场景**？  
   - 将视觉感知转化为符合人类期望的导航行为。  
3. **如何解决VLM实时性瓶颈**？  
   - 确保导航决策延迟不影响人机交互流畅性。  

---

### **提出的贡献**  
#### 1. **VLM-Social-Nav框架**  
   - **架构设计**（图2）：  
     - **感知层**：YOLO [17] 实时检测社交实体（人、手势、门）。  
     - **推理层**：GPT-4V [14] 解析场景，生成**理想人类行为** \(\mathcal{B}_h\)。  
     - **规划层**：DWA运动规划器 [18] 融合社交代价 \(\mathcal{C}_{\text{social}}\)。  
   - **社交代价函数**（公式2-4）：  
     - 定义 \(\mathcal{C}_{\text{social}} = \| \mathcal{B} - \mathcal{B}_h \|\)，最小化机器人与人类行为偏差。  
     - 将VLM输出的方向/速度指令 \((\delta_d, \delta_s)\) 转为速度差代价（线性权重 \(w_l\), 角速度权重 \(w_a\)）。  

#### 2. **提示工程优化实时性**  
   - **结构化提示**（图3）：  
     - 输入当前图像 \(\mathcal{I}^t\)、机器人动作 \(\mathbf{a}^t\)（速度/方向）、任务描述。  
     - 输出限定格式（例："HEADING: left; SPEED: slower"），降低VLM响应延迟至 **2-3秒**。  
   - **感知过滤**：仅当检测到社交实体（如人、手势）时查询VLM，减少冗余调用。  

#### 3. **实验验证**  
   - **场景设计**：4类社交导航场景（图4）：  
     - 正向接近、带手势正向接近、交叉路径、狭窄门口。  
   - **性能对比**（表I）：  
     | **指标**     | **VLM-Social-Nav** | **DWA** | **BC** |
     | ------------ | ------------------ | ------- | ------ |
     | 平均成功率   | **85.71%**         | 64.29%  | 59.52% |
     | 平均碰撞率   | **9.52%**          | 28.57%  | 30.95% |
     | 用户研究评分 | **4.21/5**         | 3.52/5  | 3.17/5 |
   - **关键结果**：  
     - 成功率提升 **27.38%**，碰撞率降低 **19.05%**。  
     - 唯一成功响应**手势指令**的方法（图4b）。  
   - **用户研究**（图5, 表II）：  
     - 问卷评估社会合规性（例："机器人尊重我的个人空间"）。  
     - VLM-Social-Nav 在所有问题上评分最高（平均 **4.21/5**）。  

---

### **创新点与局限性**  
- **创新**：  
  - **首篇融合VLM与运动规划**的社交导航框架，免除数据训练需求。  
  - **提示工程实现文化适配**：通过修改提示（例："靠左通行"）适应不同地区规则。  
- **局限**：  
  - VLM延迟（2-3秒）限制高动态场景应用（Section IV-E）。  
  - 未验证多人群场景（Section V）。  
  - 依赖GPT-4V闭源模型，未来将探索开源VLM（如LLaVA [43]）。  

> **原文结论**："VLM-Social-Nav利用VLM的常识推理生成社交代价，在四个真实场景中显著提升社会合规性，且无需训练数据或手工规则。"（Section V）  

---
**分析依据**：严格遵循论文中的框架设计（Section III）、实验设置（Section IV-A）、数据结果（Table I, Figure 5）及讨论（Section IV-E）。未引入外部知识。

## **20.** Hey Robot! Personalizing Robot Navigation through Model Predictive Control with a Large Language Model
**嘿，机器人！结合大语言模型和模型预测控制实现个性化机器人导航**

根据论文内容，以下是针对研究背景、核心研究问题及提出的贡献的概括性分析：

------

### **研究背景**

1. **环境依赖的行为需求**
    移动机器人在不同应用场景（如医院、仓库）中需满足特定行为要求（如安全性、社交性、效率）。现有导航方法普遍​**​缺乏终端用户可配置性​**​，无法根据环境动态调整行为优先级（如医院中需低速谨慎，仓库需高效），易导致不理想行为（如医院中快速行驶）。
2. **用户配置的技术门槛**
    行为配置通常需通过调整运动控制器的​**​成本函数​**​实现，但需专业知识（如系统动力学、参数调优），普通用户难以操作。预先为所有场景设计行为策略也不可行，且需求可能随时间变化（如人类对机器人的适应程度变化）。
3. **LLM/VLM的潜力**
    大语言模型（LLM）和视觉语言模型（VLM）具备自然语言与图像理解能力，可解析用户指令（如“减速”“远离人群”），为实时行为配置提供新途径。

------

### **核心研究问题**

**如何让终端用户通过自然语言指令（或环境图像）实时、安全地个性化机器人导航行为，而无需专业控制理论或编程知识？**

- 关键挑战包括：
  - **零样本适应**：无需场景预训练，直接理解新指令。
  - **行为-控制映射**：将语言指令转化为运动控制参数（如成本函数权重）。
  - **安全性保障**：在动态环境中保持避障约束，避免因行为调整引发碰撞。

------

### **提出的贡献**

论文提出 **"Hey Robot!"** 框架，核心贡献如下：

#### **1. 零样本成本函数生成与调优方法**

- 机制：
  - 使用LLM/VLM解析用户自然语言查询（如"保持与行人距离"）或机器人摄像头图像。
  - **自动生成代码**：将指令转化为MPC成本函数（如路径跟踪项、速度惩罚项）的可执行代码。
  - **参数调优**：通过LLM评估各成本项重要性（0-10分），动态计算权重（`w_α = z_α / \overline{z}`），并调整物理参数（如参考速度`v_{ref}`）。
- 创新点：
  - **无需训练**：利用预训练模型实现零样本适应。
  - **多模态输入**：支持语言指令与环境图像双通道配置。

#### **2. 可重构的MPC运动规划框架**

- 架构设计
  - 四助手系统
    - **能力助手**：判断指令类型（需新成本函数/参数更新/环境感知）。
    - **成本生成助手**：生成新成本函数代码（重用预定义项或创建新项）。
    - **相机助手**：用VLM分析环境图像（如识别"医院"场景），输出行为建议。
    - **权重调优助手**：分配成本项权重与环境参数。
  - **安全约束**：硬性避障约束（人/静态障碍）确保行为调整不危及安全。
- 创新点
  - **实时重构**：用户新指令触发MPC成本函数/参数的动态更新（平均响应时间<7秒）。
  - **全局优化**：多路径采样避免局部最优（基于同伦类拓扑）。

#### **3. 仿真与实物实验验证**

- 评估维度：
  - **助手可靠性**：成本生成成功率>90%，权重调优符合预期（如"加速"指令提升`v_{ref}`）。
  - 导航性能：
    - **任务切换**（图5）：成功实现"跟踪路径"→"跟随最近行人"行为切换。
    - **行为个性化**（表5）：指令如"医院中谨慎行驶"显著降低速度（`v_{mean}`: 1.41 m/s vs 默认2.49 m/s），增大行人距离（`d_{min}`: 0.10 m vs 默认0.51 m）。
    - **零碰撞**：所有实验满足避障约束。
  - **实物演示**：TurtleBot 2在4人动态环境中实时响应用户指令（图6）。

------

### **总结**

该研究通过**LLM/VLM+MPC融合框架**，解决了移动机器人在动态环境中**用户可配置导航行为**的核心问题。其贡献在于：

1. **零样本指令映射**（语言/图像→成本函数），
2. **安全实时的MPC重构机制**，
3. **多场景验证**（仿真/实物、行为/任务个性化）。
    该方法显著降低用户配置门槛，为机器人自然交互提供了新范式。

## **21.** Optimizing Underwater Robot Navigation: A Study of DRL Algorithms and Multi-Modal Sensor Fusion
**水下机器人导航优化：深度强化学习算法与多模态传感融合研究**

###  **研究背景**

 本文指出，水下环境具有可见度低、地形复杂且环境条件不可预测等特点，使得水下自主导航面临重大挑战。传统的传感器和定位方法（如声纳）在水下环境中往往因分辨率低、帧率慢而难以满足实时避障与高精度导航的需求；与此同时，基于静态地图和预定义路径的传统规划方法缺乏对动态环境的适应能力，无法实现对复杂水下地形的实时决策与规避［1］。随着深度强化学习（Deep Reinforcement Learning, DRL）的发展，研究者开始尝试将其应用于移动机器人导航，以期通过自主学习提高系统对变化环境的适应性。但现有方法常常难以有效融合多源传感器信息，也难以在不同水下场景中保持鲁棒性与泛化能力，导致在现实中存在明显的“训练-现实”差距［9］。为此，本研究聚焦于低成本水下机器人（如BlueROV）在配备单目深度估计与回声测深（SBES）等多模式传感器的情况下，如何借助 DRL 算法与领域随机化（Domain Randomization）技术来提升导航性能和泛化能力，以突破现有研究在感知融合与实用性方面的局限性。

### **核心研究问题**

1. **DRL 算法在水下 3D 航行任务中的表现差异**：选择了多种前沿的 DRL 算法（PPO、TRPO、SAC、TD3、A2C），重点比较它们在不同水下场景下的导航精度、成功率与收敛稳定性。研究关注在集成深度估计模型（MiDaS、Depth Anything）和 SBES 测距数据后，各算法对环境变化的适应能力以及在“无地图”条件下的路径规划效果。
2. **多模式传感器融合策略的设计与优化**：通过将深度估计（由 MiDaS 或 Depth Anything 模型生成的单目深度图）与 SBES 提供的距离信息以及相对目标位置、历史动作等特征进行融合，构建包含图像深度、声纳测距、目标相对坐标和历史动作的综合观测空间，以期提升水下障碍物检测与避障能力，并在动态环境下实现稳健导航。
3. **域随机化技术对泛化能力的贡献**：在 Unity ML-Agents 模拟环境中，通过调整水下光照、材质、纹理、动态障碍物等因素，使用域随机化策略增强模型对不同视觉与动力学条件的鲁棒性，探讨该方法对模型在“训练环境”与“验证环境”（A、B 两种不同视觉风格）的性能提升程度以及对“模拟-现实”迁移的潜在价值。

### **提出的贡献**

1. **系统性比较多种 DRL 算法**：本文在五个不同场景（WP1–WP5）下对 PPO、TRPO、SAC、TD3、A2C 等算法进行了统一的训练与测试。结果表明，在集成 Depth Anything 深度估计与 SBES 数据时，TRPO 在导航成功率（超 94%）和收敛稳定性方面表现尤为突出；PPO 和 SAC 也获得了较高的初始累积奖励，但在高难度关卡中波动较大。该比较为后续选择合适算法提供了可靠依据。
2. **多模式传感器融合框架设计**：本研究提出了一种高效的观测空间融合方案：首先利用预训练的 DINOv2 编码器与特征金字塔网络（FPN）从 RGB 图像中提取多尺度特征，再串联 MiDaS/Depth Anything 生成的深度图、SBES 测距值、相对目标位置（水平距离、垂直距离、偏航角差）和历史动作，最终输入到全连接网络生成导航策略。该设计在仿真中显著提升了深度感知与避障精度，为无地图 3D 水下导航提供了可行思路。
3. **域随机化提升模型鲁棒性**：在训练过程中对水下光照、材质、动态障碍物等多项参数进行随机化操作，实验结果显示，相较于无域随机化训练，采用该策略的模型在训练中累计奖励提高了约 15%，导航成功率提升约 10%，平均行进时间在某些关卡减少约 20 秒，验证了域随机化对提升模型泛化能力与鲁棒性的显著作用。
4. **开源实现与后续扩展价值**：论文提供了完整的开源仓库（https://github.com/eather0056/BlueROV_Nav_DRL），涵盖 DRL 训练脚本、域随机化配置、深度估计模型集成示例和仿真环境设置。该资源为研究者在实际水下机器人平台上复现和扩展研究成果提供了基础，有助于缩小“模拟-现实”差距，推动无人水下系统的发展。

综上所述，本文在水下导航领域通过系统比较多种 DRL 算法、设计多模式传感器融合框架并结合域随机化策略，实现了在无地图 3D 模拟环境中对低成本水下机器人的高效导航。研究结果表明，TRPO 与 Depth Anything 模型的组合在导航成功率和稳定性方面表现最佳，域随机化进一步增强了模型的泛化能力，为后续真实环境部署奠定了基础。

## **22.** Coordinated Multi-Robot Navigation with Formation Adaptation
**具编队自适应能力的多机器人协同导航**

### **研究背景**
 多机器人系统因其在搜索与救援、智能交通和空间探索等领域的应用前景而受到广泛关注。在这些应用场景中，机器人团队需具备高度的协同与同步能力，以确保高效、安全地完成任务。具体而言，保持特定编队（如楔形、圆形等）有助于增强可视性、定位精度与运动效率。然而，现实环境往往包含狭窄走廊和复杂障碍，传统的刚性编队难以灵活通过受限空间，这严重影响了多机器人协同导航的实用性与安全性。已有的学习免费方法（如博弈论、传统路径规划与优化技术）在应对环境变化时表现有限，且计算成本高昂；而现有的学习型方法虽具备一定优势，却未能解决编队适应性与运动振荡问题。基于此，如何在复杂环境中实现多机器人编队的动态调整与平滑导航成为亟待解决的关键挑战。 

### **核心研究问题**
 本文重点探讨的核心问题是：如何使多机器人团队在动态变化的环境中（尤其是狭窄通道）保持或动态调整编队，以在确保编队完整性的同时实现安全、平稳的协同导航。具体而言，包括两个子问题：

1. **编队适应性（Formation Adaptation）**：当路径宽度不足以容纳原始刚性编队时，如何让机器人团队及时感知环境约束并调整各自之间的相对位置？
2. **运动振荡抑制（Oscillation Reduction）**：在频繁调整编队形态的过程中，如何通过控制策略减少相互之间的速度与位置变化带来的过度振荡，从而提高导航效率与安全性？
    为解决上述问题，论文旨在提出一个能够同时兼顾团队决策（编队协调）与个体控制（障碍物躲避与路径跟踪）、并集成柔性连接模型（弹簧-阻尼器）以实现编队适应与振荡抑制的统一方法。 

### **提出的贡献**

1. **Adaptive Formation with Oscillation Reduction (AFOR) 方法**：本文首次提出将弹簧-阻尼器模型引入多机器人分层学习框架，以实现编队适应与振荡抑制。其中，弹簧分量依据 Hooke 定律，通过距离偏差对机器人之间的柔性连接施加“拉回”力；阻尼器分量依据速度差异施加“减速”力，两者共同构成编队适应奖励，使团队在狭窄环境中保持紧凑编队且减少移动振荡。
2. **分层学习架构**
   - **上层图神经网络（GNN）**：将机器人团队状态表示为图结构，通过消息传递机制让各机器人共享局部信息并生成全局编队决策，有效指导团队在复杂环境中调整编队形态。
   - **下层强化学习（RL）**：基于 Proximal Policy Optimization (PPO) 算法，每个机器人利用自身观测（位置、速度、目标与障碍距离）学习连续速度输出，实现单机器人障碍物规避与路径跟踪。上层与下层策略通过统一的 PPO 损失同步更新，确保团队决策与个体控制的协同优化。
3. **综合实验验证**：论文在三种不同平台（Gazebo+ROS 标准仿真、Unity3D+ROS 高保真仿真与实际机器人硬件）中验证了 AFOR 的有效性。实验证明：
   - AFOR 在三种典型编队（圆形、楔形、直线）下均能成功通过狭窄通道，并且在成功率与编队完整性（CFI）指标上显著优于基线方法（Leader & Follower、Decentralized GNN 与不含弹簧-阻尼器模型的分层学习）。
   - 在多机器人数量变化（3 至 9 机器人）场景下，AFOR 始终保持较高的编队完整度，展现了良好的可扩展性与鲁棒性。 

综上，本文在理论与实践层面均做出了以下主要贡献：

- **首次**在多机器人协同导航中引入弹簧-阻尼器模型以实现编队动态适应与振荡抑制；
- 提出一个**统一的分层学习框架**，结合图神经网络与强化学习，通过统一的 PPO 算法对团队决策与个体控制进行联合训练；
- 在实际场景（包括仿真与真实机器人平台）中**系统验证**了方法的有效性和可扩展性，为未来多机器人系统的复杂场景部署提供了新的思路与基准。 

## **23.** E2Map: Experience-And-Emotion Map for Self-Reflective Robot Navigation with Language Models
**E2Map：结合语言模型的具自我反思能力的经验与情绪地图导航**

### **研究背景**
 近年来，大型语言模型（LLMs）因其具备丰富的世界知识和推理能力，已被广泛尝试用于指导机器人执行各类任务，包括导航与操作。然而，现有方法往往针对静态环境设计，主要依赖 LLM 对场景的先验知识进行路径规划，却缺乏将机器人在运动过程中真实经历纳入决策的能力。真实环境具有高度不确定性与动态性（如行人突然出现、门意外开启等），仅凭 LLM 生成的初始计划在此类情形下易导致任务失败。为克服这一瓶颈，本文受人类情感机制启发，提出了一种融合机器人自身“情感”反馈的空间表示——Experience-and-Emotion Map（E2Map），以便机器人在遭遇突发事件后，能够基于既往经历实时调整行为策略，从而提升在非静态环境中的导航性能与鲁棒性。

### **核心研究问题**

1. **如何构建融合视觉语言特征与情感参数的空间地图？**
   - 需要设计一种空间网格表示（E2Map），既包含环境中每个网格单元的视觉语言特征（来自预训练视觉语言模型），又包含以多元高斯形式建模的“情感”参数，用以反映机器人对特定位置的负面或正面体验。
2. **当机器人在导航过程中遭遇突发事件时，如何利用 LMM（大规模多模态模型）与 LLM 生成事件描述与情感评估，并据此更新 E2Map？**
   - 必须设计一套流程：首先通过事件描述模块（Event Descriptor）对碰撞或突发场景进行语言化描述；然后由情感评估模块（Emotion Evaluator）对描述内容进行打分（包含“困扰度”和“负罪感”），得到综合情感分数；最后基于该情感分数调整对应网格单元的高斯分布参数，实现一次性（one-shot）“自我反思”式的地图更新。
3. **如何在 E2Map 的基础上进行路径规划，使机器人能够在一次事件后的重新规划中自动避开“负面情感”所指示的危险区域？**
   - 需要将 E2Map 中每个网格单元的情感值作为代价函数，与目标点的吸引力结合，利用现成的代价式路径规划算法（如 D*），生成更新后的安全路径，并由 MPPI 控制器执行。
4. **所提出的方法在模拟与真实环境中的性能表现如何？**
   - 通过三种典型场景（静态障碍物加入、人墙动态碰撞、门意外开启）分别测试 E2Map 方法与已有基于 LLM 的导航（LM-Nav、VLMaps）在任务成功率与行为调整能力上的差异，并在 Gazebo 仿真及真实室内环境中进行验证。

### **提出的贡献**

1. **E2Map：结合“情感”与视觉语言特征的空间表示**
   - 提出将环境映射为多通道网格，其中一部分通道存储每个单元的视觉语言特征（通过预训练 LSeg 等 LMM 提取），另一部分通道存储以多元高斯方式表示的情感参数（“困扰度”和“负罪感”）。这种设计既能利用 LLM 对物体与空间的先验知识，又可通过经验更新不断调整地图代价值。
2. **基于 LMM 与 LLM 的事件描述与情感评估管线**
   - 设计了“事件描述模块”（Event Descriptor），使用 GPT-4o 对连续三帧图像生成语言化的事件描述；以及“情感评估模块”（Emotion Evaluator），使用 Llama3 对事件描述进行二维打分（困扰度、负罪感），最终计算综合情感分数。该分数用于更新 E2Map 中被影响网格单元的高斯协方差与权重，实现一次性行为调整（one-shot behavior adjustment）。
3. **基于 E2Map 的导航系统**
   - 将情感映射视作代价场，与目标吸引力共同输入 D* 算法，生成最小代价路径；机器人使用 MPPI 控制器执行路径。在机器人遭遇突发事件后，通过更新 E2Map 并重新调用规划器，实现对“危险区域”自动避让。
4. **实验验证与性能提升**
   - 在 Gazebo 仿真环境的三种场景下进行对比实验，结果表明：在纯静态环境中，E2Map 达到 10/10 成功率，与 VLMaps 持平；而在“静态新增障碍物”、“人-墙撞击”和“动态门”场景中，E2Map 均取得了 9/10 的成功率，显著优于 LM-Nav 与 VLMaps（均为 0–1/10）；此外，在真实室内场景复现“静态障碍物”和“人墙动态”场景时，同样获得了 9/10 以上的成功率，验证了方法在现实部署中的可行性。
5. **开源实现与可扩展性**
   - 论文提供了完整的开源仓库，包括 E2Map 的构建与更新代码、基于 GPT-4o 和 Llama3 的提示设计示例、仿真环境设置以及真实机器人平台代码。该实现可为后续研究者在更复杂或更大规模的动态环境中进行扩展奠定基础。

**24.** ==HSRL: A Hierarchical Control System Based on Spiking Deep Reinforcement Learning for Robot Navigation==
**HSRL：基于脉冲深度强化学习的机器人导航分层控制系统**

**25.** ==Affordance-Based Explanations of Robot Navigation==
**基于可供性理论的机器人导航解释方法**

## **26.** Real-Time Safe Bipedal Robot Navigation Using Linear Discrete Control Barrier Functions
**基于线性离散控制屏障函数的实时安全双足机器人导航**

###  **研究背景**
 随着仿人机器人在人类环境中（如仓储、装配线等）执行任务的需求不断增加，实时、安全地在复杂环境中导航已成为关键挑战。仿人机器人由于双足行走时存在单侧接触点的本质，导致其运动高度欠驱动（underactuated），如果路径规划未充分考虑机器人动力学特性，则极易失稳跌倒。此外，仿人机器人的全阶动力学模型既高维又混有非线性、混合结构，使得直接利用全阶模型进行长航时路径规划在计算上近乎不可行。已有方法往往将路径规划与步态控制解耦——先基于环境进行无碰撞路径搜索，再设计反馈控制器跟踪该路径；但这种“先规划后控制”的模式在仿人机器人上无法保证行走稳定性，尤其在障碍物密集区域更难实时应对。为了降低计算成本，研究者引入线性倒立摆（LIP）等简化模板模型，对机器人中心质心（CoM）动态进行近似，从而能够在较低维度下规划足端位置。但现有基于 LIP 的方法仍面临：一是如何同时兼顾路径规划与步态稳定，二是如何在保持实时性的前提下，为复杂障碍环境提供有效的避障约束，这些问题成为实现仿人机器人群体部署的瓶颈。 

### **核心研究问题**
 本文聚焦的核心问题可概括为：如何在仿人机器人欠驱动动力学约束下，构建一个能够在线实时求解的、可同时规划路径与步态的框架，并在障碍物密集环境中保障行走稳定与安全。具体而言，存在以下两个子问题：

1. **路径与步态的统一规划**：传统方法多将路径规划与步态控制分离，然而欠驱动仿人机器人若仅按几何路径行走，会因重心动态不受控而导致跌倒。因此，需要设计一种基于简化动力学（如 LIP 模型）的预测模型（Model Predictive Control, MPC），使机器人在运动过程中既能选择安全的足端落点，又能确保 CoM 动态可稳定跟踪。
2. **实时可解的安全避障约束**：使用 LIP 模型虽可降低状态维度，但若直接将障碍物的非线性边界纳入 MPC 约束，仍会导致优化问题成为非线性规划，无法达到实时在线求解的要求。如何将障碍表示为线性的可行约束，同时兼顾动力学与行走极限（如足端可达范围、身体速度限制等），是实现实时避障的关键。 

### **提出的贡献**

1. **带航向角的三维 LIP 模板模型与 LIP-MPC 统一框架**
   - 本文首先将传统二维 LIP 模型扩展为包含航向角 θ 及其转向速率 ω 的三维 LIP（3D-LIP）模型，使得模型状态定义为 $px, vx, py, vy, θ$，控制输入为足端位置 $fx, fy$ 及转向速率 ω；这样既可描述机器人 CoM 在全局坐标系中的运动，又能在局部坐标系中对步态 kinematic 约束进行建模。基于该离散化的 3D-LIP 模型，构建了一个以步到步（step-to-step）动力学为基础的 MPC 优化问题（LIP-MPC），其中代价函数设计为预测 N 步后 CoM 位置与目标位置之间的距离平方和，从而实现路径与步态的联合优化。 
2. **航向角预处理与运动学约束线性化**
   - 为了在线实时求解 MPC，需将原本含有航向角 θ 的非线性运动学约束（如身体速度限制、足端可达范围、转弯时速度衰减等）线性化。论文提出通过两种策略预先计算各步的转向速率 ω̄ₖ（全球目标导向或子目标导向），并在 MPC 求解时将 ω̄ₖ 固定为常数。这样，在第 k 步内，可以将身体纵向/横向速度在本地坐标系下的上下限约束写成线性不等式；同理，将足端与 CoM 之间的最大可达距离约束按局部坐标的纵横分量分别限制，也可形式化为线性约束。此外，引入转向速率与纵向速度耦合的可机动性约束（如 vx ≤ vxₘₐₓ − α·|ωₖ|·(π⁻¹)），保证机器人在急转弯时自动减速行走。所有上述运动学约束均可在 MPC 优化中表示为线性不等式，从而保证问题是带线性约束的二次规划，可在真实时间内求解。 
3. **线性离散控制屏障函数（LDCBF）用于障碍物避让**
   - 直接将障碍物几何边界（如圆形、椭圆或多边形）纳入 DCBF 约束，会产生非线性约束，难以实时求解。为此，本文提出一种近似思想：首先对障碍物做凸包外包（若原障碍不规则，则使用包含它的凸多边形替代），并在机器人当前位置处，计算凸多边形与机器人离散 CoM 位置 x⃗ʳ 次最近点 c⃗ 及其法向量 η。基于此，定义 LDCBF h(x) = ηᵀ(x⃗ − c⃗) ≥ 0，即半空间约束。将 h(xₖ₊₁) + (γ − 1)·h(xₖ) ≥ 0 代入离散动力学后，可将避障约束转化为对控制输入 uk 的线性不等式。对于多个障碍物，则为每个障碍添加一条线性约束，所得安全区域为所有半空间的交集。该设计避免了非线性规划，确保在 MPC 内可通过 QP 快速计算出既安全又满足动力学的足端落点。 
4. **仿真验证及性能评估**
   - 在 MuJoCo 仿真平台中，选用 Agility Robotics 的 Digit 机器人，构造包含多达八个多边形障碍的随机环境，将起点设为 (0,0)，目标点 (10,10)。在参数设置（CoM 高度 H=1 m、步时 T=0.4 s、预测步数 N=3、更新频率 20 Hz）下，对比了全球目标导向和子目标导向两种航向预处理策略。结果表明：
     1. **全球目标导向**：航向角在行走过程中基本保持指向最终目标，缺乏灵活性，当障碍分布在前进方向时，会以较慢的侧向步行避让，平均耗时约 31 s（≈75 步）到达目标；
     2. **子目标导向（结合 RRT 子目标）**：先通过 RRT 规划若干中间点，再分别朝子目标行走，可使机器人更多以纵向前行方式穿越障碍区，最终耗时约 26 s（≈62 步），航向变化更频繁、路径更平滑，同时纵向速度维持更高水平。
   - 仿真结果验证了本文 LIP-MPC + LDCBF 方案在保证行走稳定和实时避障方面的可行性与有效性。 

综上所述，本文的主要贡献在于：

- **提出一种带航向角的 3D-LIP 模板模型**，并基于该模型构建实时可解的 LIP-MPC，将路径规划与步态生成统一在同一框架内。
- **通过航向角预处理，实现运动学约束的线性化**，使得足端可达性、身体速度限制、转向速度耦合等约束在 MPC 中均为线性不等式，从而满足在线 QP 求解需求。
- **设计并引入线性离散控制屏障函数（LDCBF）**，为凸障碍提供半空间安全约束，将非线性避障问题转化为线性约束形式，实现实时、安全的避障规划。
- **在 MuJoCo 仿真中对 Digit 机器人进行验证**，分别展示了全球目标导向和子目标导向两种策略下的导航性能，证明方法具有实时性、鲁棒性和较好的行走效率。 

## **27.** Language-Conditioned Offline RL for Multi-Robot Navigation
**面向多机器人导航的语言条件离线强化学习**

###  **研究背景**

 近年来，自然语言作为人机交互接口在机器人领域得到越来越多的关注。利用自然语言指令来描述机器人任务，比起传统的坐标或关节配置方式，更加直观灵活。然而，现有基于大型语言模型（LLM）的机器人控制方法多采用“生成文本→映射动作”或“开环执行文本序列”的方式，这两种方式都存在明显局限性：前者因语言模型推理延迟（通常数百毫秒到数秒）难以满足动态场景的低延迟闭环控制需求，后者由于无法实时响应环境变化而容易导致任务失败；尤其是在多机器人系统中，机器人需要快速对彼此状态变化做出反应，单纯依赖 LLM 输出的文本序列无法保证实时协同与避碰。此外，训练多机器人集体行为通常依赖仿真环境或专家示范数据，但这一类方法在现实场景中往往面临“模拟—现实”差距或数据获取成本过高的问题。因此，如何结合 LLM 的语言理解能力与低延迟、高鲁棒性的多智能体控制策略，成为亟需解决的挑战。

### **核心研究问题**

1. **如何通过 LLM 嵌入实现低延迟多机器人闭环控制？**
    传统思路是将自然语言指令输入 LLM，每次推理生成动作或动作序列，但这会带来数百毫秒到数秒级的控制延迟，不适用于动态避碰。在本工作中，作者将 LLM（具体为特征抽取型 LLM）与控制策略“解耦”，仅在任务发生变化时对自然语言指令进行一次推理，得到固定的任务嵌入；在控制环内，策略直接使用该嵌入，无需再次调用 LLM，从而实现了<2ms 的低延迟闭环控制。
2. **能否仅用少量纯随机动作收集的单机数据，通过离线强化学习训练出有效的多机器人任务条件控制策略？**
    由于在现实环境中收集多机器人动作数据代价高昂，作者提出只用一台机器人做随机游走数据收集，再通过“组合”方式构造多机器人数据：将单机数据任意组合成多智能体状态元组，同时为每个机器人分配不同的自然语言任务嵌入，从而在离线环境中构造出海量多机器人数据。核心问题在于，这种基于单机随机数据的离线数据集，是否足以训练出满足多机器人导航需求的策略，并且能够支持任务条 件化。
3. **在这种离线多智能体学习框架下，应采用何种价值函数目标保证训练稳定性并减少过度外推？**
    离线强化学习常面临 Q 值过度外推的问题。文中探讨了包括 Max Q、Mean Q、Soft Q（温度正则化）以及 CQL（保守 Q 学习）等多种目标函数在多智能体场景中的适用性，并重点关注其对离线数据外推误差的影响，以及在现实机器人系统上的执行效果。
4. **在现实多机器人系统中，该方法能否在不微调的情况下直接部署并成功执行未见过的自然语言指令？**
    最终指标不仅是模拟环境中的表现，还包括在真实机器人平台上的部署效果。核心问题在于：所训练出的策略能否对训练时未见的自然语言导航任务（“零-shot”任务）表现出足够的泛化能力，并且在真实环境中保持低碰撞率和高成功率。

### **提出的贡献**

1. **提出了一种低延迟的多智能体自然语言导航架构**：
   - 利用特征抽取型 LLM（sentence similarity LLM）将自然语言指令映射为固定维度的任务嵌入，并仅在任务改变时进行一次推理，避免了在控制环内频繁调用 LLM，从而实现<2ms 的感知-动作闭环延迟。
   - 各机器人在执行过程中，通过并行的图神经网络（GNN）结构将自身观测与所有机器人的任务嵌入进行信息融合，生成任务条件化状态表示。这种设计既保留了 LLM 对语言的理解能力，又保障了多机器人在动态场景中的实时性与协同性。
2. **设计了基于单机随机数据的多机器人离线数据集构造方法**：
   - 使用一台 DJI RoboMaster 机器人以统一分布随机采样动作，收集到包含位置、速度、动作等信息的单机转移数据集（90 分钟，5400 条样本）。
   - 线下将单机数据任意组合为多智能体状态转移元组，同时独立为每个机器人采样不同的自然语言任务嵌入，从而在不实际收集多机并行数据的情况下构造出理论上高达10³⁰可能的多机器人离线数据。该方法大幅降低了物理实验成本，为离线 MARL 提供了丰富数据来源。
3. **提出并比较了多种离线 Q 学习目标函数在多智能体导航任务下的有效性**：
   - 将 Expected SARSA 理论框架扩展至离线多智能体场景，结合“Mean Q”（基于均值运算符）、“Soft Q”（温度正则化）、“Max Q”以及 CQL（保守 Q 学习）四种目标函数，评估它们在离线数据集上的训练稳定性与实际导航性能。
   - 实验结果表明，强调数据内分布行为的 Mean Q 和 Soft Q 目标在离线学习时能有效抑制 Q 值过度外推，获得更低的收敛偏差、更少的碰撞次数以及更小的终点误差；而 Max Q 容易在训练中受到过度外推影响，CQL 虽能缓解该问题但相对更保守。
4. **验证了极高的数据效率及现实环境下的“一次训练、零微调”部署能力**：
   - 在模拟环境中，使用仅 22 分钟的单机数据即可训练出有效策略，并在少于 4 分钟数据情况下仍能获得初步可用的导航能力。
   - 在三机器人和五机器人真实平台实验中，使用 Mean Q 和 Soft Q 目标训练的策略在训练任务（10/10、19/20）和未见任务（8/10、18/20）上均取得高成功率，且在 40 分钟（3 机）与 20 分钟（5 机）的测试中几乎零碰撞，仅出现两次与边界系统误差相关的小剐蹭，证明了模型零微调即可直接部署的实用性。
5. **首个离线多智能体 RL 在真实机器人上的演示**：
   - 本文首次展示了仅凭离线收集的单机随机数据、结合自然语言嵌入与 Expected SARSA 变体目标，训练出的多智能体控制策略能够在真实机器人上执行复杂的自然语言导航任务，展现出对未见指令的泛化与各机器人之间的协同避碰能力，为“LLM + 离线 MARL”在现实机器人系统中的应用提供了开创性范例。

综上所述，该论文在“无需仿真与环境模型、使用极少数据、实现低延迟且具备泛化能力的多机器人语言条件导航”方面做出了开创性探索，提出了从单机随机数据构造多机离线数据、低延迟 LLM 嵌入解耦、以及多种 Q 学习目标函数对比验证等一整套方法论，为未来更多复杂任务的多机器人离线强化学习奠定了基础。

**28.** ==PaTS-Wheel: A Passively-Transformable Single-Part Wheel for Mobile Robot Navigation on Unstructured Terrain==
**PaTS-Wheel：适用于非结构化地形移动机器人导航的被动可变形单体轮**

## **29.** Differentiable Composite Neural Signed Distance Fields for Robot Navigation in Dynamic Indoor Environments
**用于动态室内环境中机器人导航的可微复合神经符号距离场**

### **研究背景**
 随着服务机器人在室内环境中执行任务的需求不断增加，机器人需在仅依赖自身RGB-D传感器的条件下，应对环境中不断移动和遮挡的障碍物，实现实时、安全的路径规划（见图1）。传统方法常假设环境静态或完全可观测，无法满足实际室内场景中障碍物随机移动、视野受限的需求。签名距离场（Signed Distance Field, SDF）因其可微分性和明确的碰撞梯度信息，被广泛用于基于梯度的轨迹优化，但直接采用神经网络重建完整环境的SDF需要昂贵的重训练和全局观测，对动态、局部感知的场景而言并不实际。针对这一挑战，本文提出了一种在动态、部分可观测室内环境中，利用仅有的机器人中心RGB-D信息与先验知识，构建可微分复合SDF表示以支持高效避障与轨迹优化的框架。 

------

### **核心研究问题**

1. **动态环境下的可微分环境表示**
    如何在仅依赖机器人自身RGB-D帧、无法获取全局视图的情况下，使用神经SDF对场景中不断移动的多种物体进行建模，并生成可用于计算碰撞代价与梯度的环境表示？文中强调，如果对整个场景进行全域训练或多次重训练，成本高且不具实时性；若仅依赖局部点云则易陷入局部最优。
2. **高效的轨迹优化算法设计**
    在获得环境的可微分SDF表示后，如何设计一种既能快速响应局部障碍改变、又能在必要时切换到更全局的场景SDF推理，以获得更加准确的碰撞梯度，从而引导机器人生成安全、光滑的行进路径？该问题要求协调“机器人本体SDF”与“场景复合SDF”两种管线，以兼顾计算效率与全局信息质量。 

------

### **提出的贡献**

1. **可组合的神经SDF框架**

   - **对象级SDF（Object-level SDF）**：使用DeepSDF离线预训练得到一系列常见室内物体（如家具、箱包等）的对象级神经SDF模型 $Ωᵢ(x;zᵢ)$，其中zᵢ是对应物体的形状隐向量。
   - **场景级SDF（Scene-level SDF）**：使用iSDF从深度图像连续学习场景静背景（如墙壁、地面）的SDF表示 $Ωₛ(x)$。
   - **复合场景SDF推理**：实时将检测到的可移动物体点云与其离线预训练的对象级SDF进行最优对齐（求解平移+平面旋转），生成每个物体在当前时刻的变换H, 进而通过式(2)：

   > Ω(x) = min ( Ωₛ(x),  minᵢ Ωᵢ(Hᵢ x) )

   组合得到可微分的“可见场景SDF”用于轨迹优化。 

2. **机器人本体SDF管线**

   - 直接使用DeepSDF预训练的机器人模型SDF $Ωᵣ(x)$，将其“沿轨迹扫掠”（swept volume）后，对当前可见障碍物点云Xₒ逐点查询得到碰撞代价与梯度。
   - 定义轨迹优化目标函数LR（式(4)），在仅使用机器人本体SDF下快速更新轨迹：

   > LR(Xᵣ,Xₒ) = ∑ᵢ ∑_{x ∈ Xₒ} αᵢ e^{−Ωᵣ(Mᵢ x)}  + λ ∑‖xᵢ₊₁ − xᵢ‖²

   其中，Mᵢ为将障碍点投影到机器人SDF坐标域的变换矩阵，αᵢ仅在机器人与障碍距离小于安全裕度ζ时才生效。该管线计算量低，适用于小规模或微小动态变化的场景。 

3. **双模式（Dual Mode）轨迹优化算法**

   - **主模式（Robot SDF）**：每个时刻仅使用机器人本体SDF管线进行局部轨迹更新，速度快且无需对整个场景进行SDF推理。
   - **备选模式（Scene SDF）**：当主模式下的轨迹优化无法跳出局部碰撞（检测到在当前障碍下失败）时，触发场景级SDF推理：先执行对象检测与点云分配，将点云投影到对应的对象级SDF，通过对齐得到最新的物体位姿集合{(Ωᵢ,Hᵢ)}，再调用可微复合场景SDF Ω(x)（式(2)）来重新优化轨迹。场景模式虽计算较慢，但提供更全局的碰撞梯度，能帮助机器人跳出局部极小值。
   - 该双模式算法如算法1所示，当“Robot SDF模式”检测轨迹仍处于碰撞时，才切换为更昂贵的“Scene SDF模式”，然后再回退到Robot SDF模式继续操作。此设计在保证规划成功率的同时，大幅降低平均规划时间。 

4. **短时记忆模块（Memory Modules）**

   - **点云记忆（PC-Mem）**：为Robot SDF管线保存机器人周围1 m范围内的历史障碍点云，以减轻视野切换时信息丢失造成的局部最优问题。
   - **障碍物记忆（Obs-Mem）**：为Scene SDF管线保存已检测物体的位姿信息，并根据机器人与障碍物的距离分为冻结区（F）、更新区（U）和动态区（D），仅对U区内的物体执行新的对齐与位姿更新，以减少重复计算。 

5. **实验验证**

   - 在iGibson 2.0仿真环境中，使用Turtlebot4搭配Intel RealSense 435i RGB-D，随机布置80种室内物体，并每隔2 s随机移动一个障碍，比较了Dual Mode、单独Robot SDF、单独Scene SDF、EgoTrajOpt、DWA+PC-Mem及iRRT*等基线方法（表I）。结果表明：
     - Dual Mode在300次测试中的成功率达98%，较次优Robot SDF（96.33%）与Scene SDF（93.33%）均显著更高；
     - 平均累计规划时间（15.73 s）远低于单独Scene SDF（55.97 s）与其他基线方法，验证了双模式设计的效率优势。
   - 随着环境障碍密度增加，Dual Mode的性能衰减最小（图6），展示了其在高拥挤场景下的鲁棒性。
   - 最终在真实室内环境中的Turtlebot4上也进行了演示，证明方法在噪声点云与部分遮挡下仍能实时生成安全轨迹。 

------

**小结**
 本文针对动态室内场景下机器人仅依赖RGB-D局部观测、环境不断变化的挑战，提出了一种可微分复合神经SDF表示与双模式轨迹优化框架。其核心思想在于：以对象级与场景级SDF构建局部可见场景的可微分模型，同时利用机器人本体SDF进行快速局部避障。当局部优化陷入局部最优时，再切换至全局复合SDF进行更准确的碰撞成本与梯度推理，从而实现实时且高效的避障导航。实验验证表明，所提方法在成功率、规划时效性和环境密度适应性等方面均优于多种基线方案，为移动机器人在动态室内环境中的实用部署提供了可行方案。 

## **30.** Data-Driven Sampling Based Stochastic MPC for Skid-Steer Mobile Robot Navigation
**基于数据驱动采样的滑移转向移动机器人随机模型预测控制导航方法**

### 研究背景

这篇论文研究了滑移转向机器人（skid-steer robots）的导航控制问题。滑移转向机器人因其高牵引力和负载能力，在崎岖和具有挑战性的地形中被广泛应用。然而，这种机器人的机动性伴随着显著的打滑和滑移现象，尤其是在高速行驶时，其运动预测变得异常困难。传统的运动建模方法，如基于简单运动学模型的方法，难以准确捕捉轮胎与地形之间的复杂非线性动态特性，尤其是在不同地形和高速条件下。因此，研究背景聚焦于如何克服这些挑战，以实现滑移转向机器人在动态环境中的安全、高效导航。

---

### 核心研究问题

论文的核心研究问题是：**如何在复杂地形和高速运动下，准确建模滑移转向机器人的运动，并实现安全可靠的路径跟踪和障碍物规避控制**。具体而言，传统的运动模型无法有效处理由于打滑和滑移导致的非线性动态和不确定性，而这些因素在高速导航和多地形条件下尤为突出。因此，研究需要解决如何开发一种自适应的、考虑不确定性的控制方法，以确保机器人在不同场景下的导航性能。

---

### 提出的贡献

论文提出了一种基于数据驱动的随机模型预测控制方法（GP-MPPI），针对滑移转向机器人的导航问题给出了以下关键贡献：

1. **自适应运动建模**  
   - 通过高斯过程回归（Gaussian Process Regression, GPR）增强了动态独轮车模型，捕捉轮胎与地形之间的非线性动态特性。
   - 利用GPR预测运动中的不确定性，并通过训练多个地形（如草地、沥青、瓷砖）的GP模型，实现对不同地形条件的自适应建模。
   - 采用加权组合方法，根据机器人状态历史优化地形权重，从而提高模型的适应性和准确性。

2. **机会约束控制**  
   - 将GPR与模型预测路径积分（Model Predictive Path Integral, MPPI）控制框架结合，引入机会约束（chance constraints）。
   - 通过考虑GP模型预测的残差不确定性，确保路径跟踪和障碍物规避的安全性和可靠性，满足高概率的安全约束。

3. **统一的导航解决方案**  
   - 设计了定制的成本函数，将路径跟踪和障碍物规避任务整合到一个统一的GP-MPPI框架中。
   - 该方法适用于多种导航场景，避免了传统方法仅关注单一任务的局限性，提供了一个全面的解决方案。

4. **实时性能**  
   - 利用GPU并行加速技术，高效处理非凸优化问题，实现实时导航控制（运行频率达20 Hz）。
   - 通过并行采样和GP推理，显著降低了计算开销，确保方法在高速导航中的实用性。

---

### 总结

这篇论文围绕滑移转向机器人在复杂地形和高速条件下的导航控制问题展开，提出了一个基于高斯过程回归和模型预测路径积分的随机控制框架（GP-MPPI）。通过自适应建模、机会约束控制、统一导航任务和实时优化，该方法有效解决了传统运动学模型的不足。论文通过大量仿真和硬件实验验证了方法的优越性，展示了其在路径跟踪精度、障碍物规避成功率以及多地形适应性方面的显著改进。这一研究为滑移转向机器人在动态环境中的安全高效导航提供了创新且实用的解决方案。